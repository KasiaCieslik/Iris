{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('no show only numeric.csv')\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>...</th>\n",
       "      <th>('SÃO CRISTÓVÃO',)</th>\n",
       "      <th>('SÃO JOSÉ',)</th>\n",
       "      <th>('SÃO PEDRO',)</th>\n",
       "      <th>('TABUAZEIRO',)</th>\n",
       "      <th>('UNIVERSITÁRIO',)</th>\n",
       "      <th>('VILA RUBIM',)</th>\n",
       "      <th>SD_date</th>\n",
       "      <th>days_between</th>\n",
       "      <th>days in week range</th>\n",
       "      <th>age_after_cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 18:38:08+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29 16:08:27+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 16:19:04+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 17:29:31+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 16:07:23+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     PatientId  AppointmentID  Gender               ScheduledDay  \\\n",
       "0           0  2.987250e+13        5642903       0  2016-04-29 18:38:08+00:00   \n",
       "1           1  5.589978e+14        5642503       1  2016-04-29 16:08:27+00:00   \n",
       "2           2  4.262962e+12        5642549       0  2016-04-29 16:19:04+00:00   \n",
       "3           3  8.679512e+11        5642828       0  2016-04-29 17:29:31+00:00   \n",
       "4           4  8.841186e+12        5642494       0  2016-04-29 16:07:23+00:00   \n",
       "\n",
       "              AppointmentDay  Age      Neighbourhood  Scholarship  \\\n",
       "0  2016-04-29 00:00:00+00:00   62    JARDIM DA PENHA            0   \n",
       "1  2016-04-29 00:00:00+00:00   56    JARDIM DA PENHA            0   \n",
       "2  2016-04-29 00:00:00+00:00   62      MATA DA PRAIA            0   \n",
       "3  2016-04-29 00:00:00+00:00    8  PONTAL DE CAMBURI            0   \n",
       "4  2016-04-29 00:00:00+00:00   56    JARDIM DA PENHA            0   \n",
       "\n",
       "   Hipertension  ...  ('SÃO CRISTÓVÃO',)  ('SÃO JOSÉ',)  ('SÃO PEDRO',)  \\\n",
       "0             1  ...                 0.0            0.0             0.0   \n",
       "1             0  ...                 0.0            0.0             0.0   \n",
       "2             0  ...                 0.0            0.0             0.0   \n",
       "3             0  ...                 0.0            0.0             0.0   \n",
       "4             1  ...                 0.0            0.0             0.0   \n",
       "\n",
       "   ('TABUAZEIRO',)  ('UNIVERSITÁRIO',)  ('VILA RUBIM',)  \\\n",
       "0              0.0                 0.0              0.0   \n",
       "1              0.0                 0.0              0.0   \n",
       "2              0.0                 0.0              0.0   \n",
       "3              0.0                 0.0              0.0   \n",
       "4              0.0                 0.0              0.0   \n",
       "\n",
       "                     SD_date  days_between  days in week range  age_after_cut  \n",
       "0  2016-04-29 00:00:00+00:00             0                 1.0             60  \n",
       "1  2016-04-29 00:00:00+00:00             0                 1.0             50  \n",
       "2  2016-04-29 00:00:00+00:00             0                 1.0             60  \n",
       "3  2016-04-29 00:00:00+00:00             0                 1.0             10  \n",
       "4  2016-04-29 00:00:00+00:00             0                 1.0             50  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary after Data Visualization\n",
    "- Age less than 0 and more than 100 should be drop\n",
    "- days between where appoitment was earlier than schedule should be drop\n",
    "- Unnamed:0 can be drop\n",
    "- Appoitment ID is unique and can be use in index\n",
    "\n",
    "Data for split \n",
    "- we should avoid that we have the same person in train and test\n",
    "- comparision for diffrent train and test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set with attributes has 74053 rows and Test set has 36474 rows\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test  = train_test_split(df,test_size=0.33,random_state=42,stratify = df['No-show'])\n",
    "\n",
    "\n",
    "print(f'Train set with attributes has {X_train.shape[0]} rows and Test set has {X_test.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target set balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_YES_train = X_train['No-show'].value_counts()[1]/X_train['No-show'].value_counts().sum()\n",
    "percent_YES_test = X_test['No-show'].value_counts()[1]/X_test['No-show'].value_counts().sum()\n",
    "#print('We have ca. 20% YES and 80% NO in both sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gander balanced sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train and test sets with attributes have 65% woman in both of them\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    65.0\n",
       "1    35.0\n",
       "Name: Gender, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Gender.value_counts()\n",
    "percent_Woman_train = round(X_train.Gender.value_counts()/X_train.Gender.value_counts().sum()*100)\n",
    "percent_Woman_test = round(X_test.Gender.value_counts()/X_test.Gender.value_counts().sum()*100)\n",
    "\n",
    "print('Our train and test sets with attributes have 65% woman in both of them')\n",
    "percent_Woman_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stratified suffle split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_target = df.drop('No-show',axis=1)\n",
    "target = df['No-show']\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "\n",
    "for train_index,test_index in split.split(df_without_target,target):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_s, X_test_s = df1.iloc[train_index], df1.iloc[test_index]\n",
    "    y_train_s, y_test_s = target[train_index], target[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unique patients in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.98724998e+13 5.58997777e+14 4.26296230e+12 ... 7.26331493e+13\n",
      " 9.96997666e+14 1.55766317e+13]\n",
      "[4.78977466e+12 9.53369388e+12 2.55683148e+14 ... 1.85534231e+13\n",
      " 6.77789954e+14 3.34356994e+14]\n"
     ]
    }
   ],
   "source": [
    "patient_list = df.PatientId.unique()\n",
    "print(patient_list)\n",
    "random.seed(42)\n",
    "np.random.shuffle(patient_list)\n",
    "\n",
    "print(patient_list)\n",
    "\n",
    "size_of_test = round(len(patient_list)*0.25)\n",
    "size_of_train = round(len(patient_list)*0.75)\n",
    "\n",
    "patient_train = patient_list[15575:]\n",
    "patient_test =  patient_list[:15575]\n",
    "\n",
    "train = df[df['PatientId'].isin(patient_train)]\n",
    "test = df[df['PatientId'].isin(patient_test)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_oberall</th>\n",
       "      <th>train_test_split_target_TRAIN</th>\n",
       "      <th>train_test_split_target_TEST</th>\n",
       "      <th>StratifiedShufflesplit_target_TRAIN</th>\n",
       "      <th>StratifiedShufflesplit-taget_TEST</th>\n",
       "      <th>UniquePatients_TRAIN</th>\n",
       "      <th>UniquePatients_TEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.798067</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.798075</td>\n",
       "      <td>0.798068</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.797537</td>\n",
       "      <td>0.799666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201933</td>\n",
       "      <td>0.201936</td>\n",
       "      <td>0.201925</td>\n",
       "      <td>0.201932</td>\n",
       "      <td>0.201936</td>\n",
       "      <td>0.202463</td>\n",
       "      <td>0.200334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_oberall  train_test_split_target_TRAIN  \\\n",
       "0        0.798067                       0.798064   \n",
       "1        0.201933                       0.201936   \n",
       "\n",
       "   train_test_split_target_TEST  StratifiedShufflesplit_target_TRAIN  \\\n",
       "0                      0.798075                             0.798068   \n",
       "1                      0.201925                             0.201932   \n",
       "\n",
       "   StratifiedShufflesplit-taget_TEST  UniquePatients_TRAIN  \\\n",
       "0                           0.798064              0.797537   \n",
       "1                           0.201936              0.202463   \n",
       "\n",
       "   UniquePatients_TEST  \n",
       "0             0.799666  \n",
       "1             0.200334  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_bias_comparision = pd.DataFrame()\n",
    "whole_set_gender = df.Gender.value_counts()/len(df1)\n",
    "sampling_bias_comparision['overall_gender'] = whole_set_gender\n",
    "\n",
    "sampling_bias_comparision_target = pd.DataFrame()\n",
    "sampling_bias_comparision_target['target_oberall'] = target.value_counts()/len(target)\n",
    "\n",
    "sampling_bias_comparision['train_test_split_gender_TRAIN'] = X_train.Gender.value_counts()/len(X_train)\n",
    "sampling_bias_comparision['train_test_split_gender_TEST'] = X_test.Gender.value_counts()/len(X_test)\n",
    "\n",
    "sampling_bias_comparision_target['train_test_split_target_TRAIN'] = X_train['No-show'].value_counts()/len(X_train['No-show'])\n",
    "sampling_bias_comparision_target['train_test_split_target_TEST'] = X_test['No-show'].value_counts()/len(X_test['No-show'])\n",
    "\n",
    "\n",
    "\n",
    "sampling_bias_comparision['StratifiedShufflesplit_TRAIN'] = X_train_s.Gender.value_counts()/len(X_train_s)\n",
    "sampling_bias_comparision['StratifiedShufflesplit_TEST'] = X_test_s.Gender.value_counts()/len(X_test_s)\n",
    "\n",
    "sampling_bias_comparision_target['StratifiedShufflesplit_target_TRAIN'] = y_train_s.value_counts()/len(y_train_s)\n",
    "sampling_bias_comparision_target['StratifiedShufflesplit-taget_TEST'] = y_test_s.value_counts()/len(y_test_s)\n",
    "\n",
    "sampling_bias_comparision_target['UniquePatients_TRAIN'] = train['No-show'].value_counts()/len(train)\n",
    "sampling_bias_comparision_target['UniquePatients_TEST'] = test['No-show'].value_counts()/len(test)\n",
    "\n",
    "sampling_bias_comparision_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will take train and test to do analysis. We use UniquePatientSplit to create this two datasets\n",
    "train = train.drop('Unnamed: 0',axis=1)\n",
    "test = test.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical \n",
    "### binary string to binary number\n",
    "class StringToBinary(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        for columns in X.columns:\n",
    "            if X[columns].dtype=='object' and len(X[columns].unique())==2:\n",
    "                X[columns] = pd.factorize(X[columns])[0]     \n",
    "        return X\n",
    "### object for a date to datetime and extra feature\n",
    "obj_date_to_datetime = ['ScheduledDay','AppointmentDay']\n",
    "class ObjectToDataTime(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,obj_date_to_time):\n",
    "        self.obj_date_to_time = obj_date_to_time\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,Y=None):\n",
    "        if self.obj_date_to_time:\n",
    "            for columns in self.obj_date_to_time:\n",
    "                X[columns] = X[columns].apply(pd.to_datetime).dt.normalize()\n",
    "            X['DaysBetween'] = DaysBetween = (X['AppointmentDay'] - X['ScheduledDay']).apply(lambda x:x.days) \n",
    "            return X\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attributes_name):\n",
    "        self.attributes_name = attributes_name\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        for columns in self.attributes_name:\n",
    "            return X[columns].values\n",
    "        \n",
    "class Get_Dummies(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return pd.get_dummies(X)\n",
    "\n",
    "obj_date_to_dt=['ScheduledDay','AppointmentDay']\n",
    "cat_pipeline = Pipeline([\n",
    "    ('StringToBinary',StringToBinary()),\n",
    "    ('ObjectToDataTime',ObjectToDataTime(obj_date_to_dt)),\n",
    "    ('GetDummies',Get_Dummies())\n",
    "])\n",
    "\n",
    "#train1 = cat_pipeline.fit_transform(train)\n",
    "#numerical\n",
    "age_range = ['Age']\n",
    "class SmallerAgeRange(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,age_range):\n",
    "        self.age_range = age_range\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        for col in self.age_range:\n",
    "            X[col][X[col]<0]=0\n",
    "            X[col][X[col]>95]=95\n",
    "        return X\n",
    "    \n",
    "class DropNaN(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        return X[~np.isnan(X).any(axis=1)]\n",
    "\n",
    "pipeline_num = Pipeline([\n",
    "    ('SmallerAgeRange',SmallerAgeRange(age_range))\n",
    "])\n",
    "#train_prep = pipeline_num.fit_transform(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8588f261c423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_prep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mready_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-ea1210781874>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m pipeline_num = Pipeline([\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "\n",
    "#y_train=train['No-show']\n",
    "#train = train.drop('No-show',axis=1)\n",
    "\n",
    "\n",
    "#full pipeline\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('cat_pipeline',cat_pipeline),\n",
    "    ('num_pipeline',pipeline_num)\n",
    "])\n",
    "\n",
    "ready_pipeline = Pipeline([\n",
    "    ('full_pipeline',full_pipeline),\n",
    "    ('DropNaN',DropNaN())\n",
    "])\n",
    "\n",
    "train_prep = ready_pipeline.fit_transform(train)\n",
    "y_train = pd.factorize(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(train_prep)\n",
    "a.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-90ee568910a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mready_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "ready_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
